name: Historical Backfill
run-name: Backfill for ${{ inputs.device || 'All' }} ${{ inputs.variant || '' }}

on:
  workflow_dispatch:
    inputs:
      device:
        description: 'Target Device (optional, e.g. 15)'
        required: false
      variant:
        description: 'Target Variant (optional, e.g. CN)'
        required: false

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

jobs:
  setup-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4
      
      - name: Cache APT Packages
        uses: awalsh128/cache-apt-pkgs-action@latest
        with:
          packages: aria2 unzip curl
          version: 1.0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Generate Backfill Matrix
        id: set-matrix
        env:
          TARGET_DEVICE: ${{ inputs.device }}
          TARGET_VARIANT: ${{ inputs.variant }}
        run: |
          # Filter logic can be added to generate_backfill_matrix.py based on inputs if needed
          python3 generate_backfill_matrix.py

  prepare-tools:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Cache APT Packages
        uses: awalsh128/cache-apt-pkgs-action@latest
        with:
          packages: aria2 unzip curl
          version: 1.0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt

      - name: Cache Tools
        id: cache-tools
        uses: actions/cache@v4
        with:
          path: tools/
          key: tools-v1

      - name: Setup Tools
        if: steps.cache-tools.outputs.cache-hit != 'true'
        run: |
          mkdir -p tools
          curl -L -o tools/arbextract https://github.com/koaaN/arbextract/releases/download/1.0/arbextract-x86_64-linux
          chmod +x tools/arbextract
          curl -L -o otaripper.tar.gz https://github.com/syedinsaf/otaripper/releases/download/v2.1.1/otaripper-2.1.1-linux-static-x86_64.tar.gz
          tar -xzvf otaripper.tar.gz
          mv otaripper tools/otaripper || find . -name "otaripper" -type f -exec mv {} tools/otaripper \;
          chmod +x tools/otaripper
          curl -L -o pdg.tar.gz https://github.com/ssut/payload-dumper-go/releases/download/1.2.2/payload-dumper-go_1.2.2_linux_amd64.tar.gz
          tar -xzvf pdg.tar.gz
          mv payload-dumper-go tools/payload-dumper-go || find . -name "payload-dumper-go" -type f -exec mv {} tools/payload-dumper-go \;
          chmod +x tools/payload-dumper-go

      - name: Ensure Tools are Executable
        run: chmod +x tools/* || true

  backfill-variant:
    needs: [setup-matrix, prepare-tools]
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      max-parallel: 20
      fail-fast: false
      matrix: ${{ fromJson(needs.setup-matrix.outputs.matrix) }}
    
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Cache APT Packages
        uses: awalsh128/cache-apt-pkgs-action@latest
        with:
          packages: aria2 unzip curl
          version: 1.0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Restore Tools Cache
        uses: actions/cache/restore@v4
        with:
          path: tools/
          key: tools-v1
          fail-on-cache-miss: true

      - name: Ensure Tools are Executable
        run: chmod +x tools/* || true
      - name: Get Firmware URL
        id: get_details
        run: |
          python3 fetch_firmware.py "${{ matrix.device }}" "${{ matrix.variant }}" "${{ matrix.version }}" --output fw_info.json
          URL=$(python3 -c "import sys, json; print(json.load(open('fw_info.json'))['url'])")
          VERSION=$(python3 -c "import sys, json; print(json.load(open('fw_info.json'))['version'])")
          MD5=$(python3 -c "import sys, json; data=json.load(open('fw_info.json')); print(data.get('md5') or '')")
          echo "url=$URL" >> $GITHUB_OUTPUT
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "md5=$MD5" >> $GITHUB_OUTPUT

      - name: Cache ARB Data
        id: cache-arb
        uses: actions/cache@v4
        with:
          path: firmware_data/
          key: arb-v9-${{ matrix.device }}-${{ matrix.variant }}-${{ steps.get_details.outputs.version }}-${{ steps.get_details.outputs.md5 }}

      - name: Download Firmware
        if: steps.cache-arb.outputs.cache-hit != 'true'
        run: |
          URL="${{ steps.get_details.outputs.url }}"
          VERSION="${{ steps.get_details.outputs.version }}"
          MD5="${{ steps.get_details.outputs.md5 }}"
          
          MAX_RETRIES=5
          RETRY_COUNT=0
          SUCCESS=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Attempting download (Try $((RETRY_COUNT+1))/$MAX_RETRIES)..."
            
            # Construct aria2c command with optional checksum
            ARIA_CMD="aria2c -c -x16 -s16 -k1M -o firmware.zip"
            if [[ "$MD5" != "" && "$MD5" != "None" ]]; then
                echo "Enforcing MD5 checksum: $MD5"
                ARIA_CMD="$ARIA_CMD --checksum=md5=$MD5"
            else
                echo "No MD5 checksum available for verification."
            fi
            
            if $ARIA_CMD "$URL"; then
              echo "Download successful!"
              SUCCESS=1
              break
            fi
            
            echo "Download failed. Refreshing URL..."
            # Remove partial/failed file
            rm -f firmware.zip
            
            RETRY_COUNT=$((RETRY_COUNT+1))
            if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then break; fi
            
            # Refresh URL
            python3 fetch_firmware.py "${{ matrix.device }}" "${{ matrix.variant }}" "$VERSION" --output fw_refresh.json
            if [ -f fw_refresh.json ]; then
               NEW_URL=$(python3 -c "import sys, json; print(json.load(open('fw_refresh.json'))['url'])")
               if [[ "$NEW_URL" != "" && "$NEW_URL" != "null" ]]; then
                  URL="$NEW_URL"
                  echo "Refreshed URL successfully."
               fi
            fi
            sleep 5
          done
          
          if [ $SUCCESS -eq 0 ]; then
             echo "Download failed after all attempts."
             exit 1 # In backfill we might want to fail the job
          fi

      - name: Analyze Firmware
        if: hashFiles('firmware.zip') != '' || steps.cache-arb.outputs.cache-hit == 'true'
        run: |
          # Pass 'firmware.zip' even if missing, analyze_firmware will skip it if cache hit
          python3 analyze_firmware.py firmware.zip --tools-dir tools --output-dir extracted --final-dir firmware_data --json > result.json
          
      - name: Update History (Historical)
        if: hashFiles('result.json') != ''
        run: |
          python3 update_history.py \
            "${{ matrix.device_short }}" \
            "${{ matrix.variant }}" \
            "${{ steps.get_details.outputs.version }}" \
            --json-file result.json \
            --historical \
            --md5 "${{ steps.get_details.outputs.md5 }}"



      - name: Upload History
        uses: actions/upload-artifact@v4
        with:
          name: history-${{ matrix.device }}-${{ matrix.variant }}-${{ strategy.job-index }}
          path: data/history/${{ matrix.device_short }}_${{ matrix.variant }}.json

  consolidate:
    needs: backfill-variant
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Download All History
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: false
      
      - name: Merge History
        shell: python
        run: |
          import os, json, glob
          from pathlib import Path
          
          artifacts = glob.glob("artifacts/history-*/*.json")
          merged = {}
          for a in artifacts:
              name = os.path.basename(a)
              with open(a, "r") as f:
                  data = json.load(f)
              if name not in merged:
                  merged[name] = data
              else:
                  # Merge history list, avoid duplicates but update missing data
                  existing_versions = {e["version"]: i for i, e in enumerate(merged[name]["history"])}
                  for entry in data["history"]:
                      if entry["version"] not in existing_versions:
                          merged[name]["history"].append(entry)
                          existing_versions[entry["version"]] = len(merged[name]["history"]) - 1
                      else:
                          idx = existing_versions[entry["version"]]
                          if "md5" in entry and "md5" not in merged[name]["history"][idx]:
                              merged[name]["history"][idx]["md5"] = entry["md5"]

          # Save merged results
          os.makedirs("data/history", exist_ok=True)
          for name, data in merged.items():
              # Sort history by date/version if possible
              data["history"].sort(key=lambda x: x.get("first_seen", ""), reverse=True)
              with open(f"data/history/{name}", "w") as f:
                  json.dump(data, f, indent=2)
                  
      - name: Generate Content
        run: |
          pip3 install jinja2
          python3 generate_readme.py
          python3 generate_site.py
          
      - name: Commit and Push
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/history/*.json README.md
          git commit -m "Backfill historical ARB data" || echo "No changes to commit"
          git push
